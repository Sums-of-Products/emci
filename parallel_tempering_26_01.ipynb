{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dcf47a6",
   "metadata": {
    "hideCode": false,
    "id": "8dcf47a6"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684d8f74",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "684d8f74",
    "outputId": "3573ac84-dc6e-45a2-d913-892aa3a8627a"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cache_f (path,max_parents,n_nodes):\n",
    "#with open('./data/scores/asia.jkl','r') as file:\n",
    "    with open(path,'r') as file:\n",
    "        filedata = file.readlines()\n",
    "    \n",
    "        \n",
    "    #line = filedata[1]\n",
    "    #print(line)\n",
    "    #print(re.findall(r'\\d+', line))\n",
    "\n",
    "    n_parents_set=[]\n",
    "    cache ={}\n",
    "    \n",
    "    \n",
    "    \n",
    "    t=1\n",
    "    vertices=[]\n",
    "    for i in range (n_nodes):\n",
    "        line = filedata[t]\n",
    "        vertices.append(int(re.findall(r'\\d+', line)[0]))\n",
    "        t+=int(re.findall(r'\\d+', line)[1])+1\n",
    "    #print(vertices)\n",
    "    \n",
    "    t=1\n",
    "    for i in vertices :\n",
    "        line = filedata[t]\n",
    "        now_n_parents_set =int(re.findall(r'\\d+', line)[1])\n",
    "        #print(now_n_parents_set)\n",
    "        n_parents_set.append(now_n_parents_set)\n",
    "        now_dict= {}\n",
    "        #print(filedata[t])\n",
    "        for j in range(now_n_parents_set):\n",
    "            now_parents=()\n",
    "            for k in range (len(re.findall(r'\\d+', filedata[t+j+1]))-3):\n",
    "                #print(re.findall(r'\\d+', filedata[t+j+1]))\n",
    "                now_parents= now_parents + (int(re.findall(r'\\d+', filedata[t+j+1])[k+3]),)\n",
    "            #now_dict[float(filedata[t+j+1].split(' ')[0])]=now_parents\n",
    "            now_parents=tuple(sorted(now_parents))\n",
    "            #if now_parents==(12,18):\n",
    "                #print(i)\n",
    "            now_dict[now_parents]=float(filedata[t+j+1].split(' ')[0])\n",
    "        cache[i]=now_dict\n",
    "        t=t+now_n_parents_set+1\n",
    "    return cache\n",
    "\n",
    "#cache=cache('insurance50003p.jkl',3,27)\n",
    "#n_parents_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be060899",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### Igraph REV functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75706af4",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true
   },
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "from src.utils import ScoreManager\n",
    "from src.mcmc import mcmc as sample\n",
    "from src.steps import REV\n",
    "\n",
    "def propose_next(G_i: ig.Graph, is_REV, beta, score_manager: ScoreManager):\n",
    "    new_edge_reversal_move = REV(score_manager, beta).new_edge_reversal_move\n",
    "\n",
    "    return new_edge_reversal_move(G_i)\n",
    "\n",
    "    \n",
    "score_manager = ScoreManager('insurance50003p.jkl')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a41f3",
   "metadata": {},
   "source": [
    "### Temporary rev(to be removed later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0e27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "\n",
    "\n",
    "class ScoreManager:\n",
    "    def __init__(self, score_name: str):\n",
    "        self.scores = read_scores_from_file(f'{score_name}.jkl')\n",
    "\n",
    "    def P(self, M: ig.Graph):\n",
    "        def f(n, G_i_count):\n",
    "            return 1 / binom(n - 1, G_i_count)\n",
    "\n",
    "        G_i_count = np.fromiter(\n",
    "            map(lambda v: len(list(M.predecessors(v))), M.vs), int)\n",
    "\n",
    "        return f(len(list(M.vs)), G_i_count).prod()\n",
    "\n",
    "    def get_local_likelihood(self, v, pa_i, n):\n",
    "        try:\n",
    "            res = self.scores[v][pa_i]\n",
    "        except KeyError:\n",
    "            res = -np.inf\n",
    "\n",
    "        return res\n",
    "\n",
    "    def get_local_prior(self, v, pa_i, n):\n",
    "        k = len(pa_i)\n",
    "\n",
    "        # Use Koivisto prior\n",
    "        prior = np.log(1 / binom(n, k))\n",
    "        return prior\n",
    "\n",
    "    def get_local_score(self, v, pa_i, n):\n",
    "        return self.get_local_likelihood(v, pa_i, n) + self.get_local_prior(v, pa_i, n)\n",
    "\n",
    "    def get_score(self, G: ig.Graph):\n",
    "        likelihood = 0\n",
    "        prior = 0\n",
    "\n",
    "        n = len(G.vs)\n",
    "\n",
    "        for v in G.vs:\n",
    "            pi = frozenset(map(lambda x: x, G.predecessors(v)))\n",
    "            local_score, local_prior = self.get_local_likelihood(\n",
    "                v.index, pi, n), self.get_local_prior(v.index, pi, n)\n",
    "\n",
    "            # If it is inf, just return\n",
    "            if (local_score == -np.inf):\n",
    "                return local_score, local_prior\n",
    "\n",
    "            likelihood += local_score\n",
    "            prior += local_prior\n",
    "\n",
    "        return likelihood, prior\n",
    "\n",
    "\n",
    "def R(likelihood_i, likelihood_i_p_1, prior_i, prior_i_p_1):\n",
    "    if (likelihood_i_p_1 == -np.inf):\n",
    "        return 0\n",
    "\n",
    "    # Prevent overlow\n",
    "    if (likelihood_i_p_1 - likelihood_i > 400):\n",
    "        res = 1\n",
    "    else:\n",
    "        res = np.exp(likelihood_i_p_1 + prior_i_p_1 - likelihood_i - prior_i)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def sample(G: ig.Graph, N: int, additional_steps, beta, score_manager: ScoreManager, show_progress=False):\n",
    "    \"\"\" Generator. \n",
    "        yields (Graph, score)\n",
    "    \"\"\"\n",
    "    G_i: ig.Graph = G.copy()\n",
    "\n",
    "    is_REV = 'rev' in additional_steps\n",
    "\n",
    "    pbar = tqdm(\n",
    "        range(N), bar_format='{desc}: {bar}') if show_progress else iter(lambda: True, None)\n",
    "\n",
    "    for i in pbar:\n",
    "        G_i_plus_1, step_type = propose_next(G_i, is_REV, beta, score_manager)\n",
    "        likelihood_i, prior_i = score_manager.get_score(G_i)\n",
    "        likelihood_i_p_1, prior_i_p_1 = score_manager.get_score(G_i_plus_1)\n",
    "\n",
    "        #print('done')\n",
    "\n",
    "        if (step_type == 'REV'):\n",
    "            G_i, likelihood_i, prior_i = G_i_plus_1, likelihood_i_p_1, prior_i_p_1\n",
    "        else:\n",
    "            A = np.min(\n",
    "                [1, R(likelihood_i*beta, likelihood_i_p_1*beta, prior_i, prior_i_p_1)])\n",
    "            if (np.random.uniform() <= A):\n",
    "                G_i, likelihood_i, prior_i = G_i_plus_1, likelihood_i_p_1, prior_i_p_1\n",
    "\n",
    "        score = likelihood_i + prior_i\n",
    "        if (show_progress):\n",
    "            pbar.set_description(f'Score: {score:.2f}')\n",
    "        #print('done')\n",
    "        return G_i, score\n",
    "\n",
    "\n",
    "def propose_next(G_i: ig.Graph, is_REV, beta, score_manager: ScoreManager):\n",
    "    a, b = random.sample(list(G_i.vs), k=2)\n",
    "    G_i_plus_1: ig.Graph = G_i.copy()\n",
    "    #print(G_i_plus_1.is_dag(),'beginning',score_manager.get_score(G_i))\n",
    "    new_edge_reversal_move = REV(beta, score_manager).new_edge_reversal_move\n",
    "\n",
    "    if (is_REV and np.random.uniform() < 1.1):\n",
    "        return new_edge_reversal_move(G_i_plus_1)\n",
    "\n",
    "    if (G_i.are_connected(a, b)):\n",
    "        print('remove')\n",
    "        G_i_plus_1.delete_edges([(a, b)])\n",
    "        #return G_i_plus_1, 'remove'\n",
    "    elif (G_i.are_connected(b, a)):\n",
    "        G_i_plus_1.delete_edges([(b, a)])\n",
    "        G_i_plus_1.add_edges([(a, b)])\n",
    "        print('reverse')\n",
    "        #if G_i_plus_1.is_dag(): \n",
    "            #print('cycle')\n",
    "            #print(score_manager.get_score(G_i))\n",
    "            #return G_i, 'reverse'\n",
    "    else:\n",
    "        G_i_plus_1.add_edges([(a, b)])\n",
    "        print('add')\n",
    "        #if G_i_plus_1.is_dag():\n",
    "            #print('cycle')\n",
    "            #return G_i, 'add'\n",
    "            \n",
    "    if G_i_plus_1.is_dag():\n",
    "        print('prime is not dag', G_i.is_dag())\n",
    "        return G_i,False\n",
    "    \n",
    "    print(G_i_plus_1.is_dag(),'step1',score_manager.get_score(G_i_plus_1))\n",
    "    likelihood_i, prior_i = score_manager.get_score(G_i)\n",
    "    likelihood_i_p_1, prior_i_p_1 = score_manager.get_score(G_i_plus_1)\n",
    "    \n",
    "    print(likelihood_i-likelihood_i_p_1)\n",
    "    A = np.min([1, R(likelihood_i*beta, likelihood_i_p_1*beta, prior_i, prior_i_p_1)])\n",
    "    if (np.random.uniform() <= A):\n",
    "        G_i, likelihood_i, prior_i = G_i_plus_1, likelihood_i_p_1, prior_i_p_1\n",
    "\n",
    "    return G_i, False\n",
    "\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from itertools import chain\n",
    "import igraph as ig\n",
    "\n",
    "def read_graph_from_file(filename, random_weights=False):\n",
    "\n",
    "    # file = open('./sample.gr', 'r')\n",
    "    file = open(filename, 'r')\n",
    "    G = nx.Graph()\n",
    "    lines = [tuple(map(int, line.strip().split(\" \"))) for line in file.readlines()]\n",
    "    nodes_count = lines[0][0]\n",
    "    edges = lines[1:]\n",
    "    \n",
    "    nodes = np.arange(1, nodes_count + 1)\n",
    "    G.add_nodes_from(nodes)\n",
    "    for edge in edges:\n",
    "        weight = np.round(np.random.normal(), 2) if random_weights else 1\n",
    "\n",
    "        G.add_edge(edge[0], edge[1], weight=weight)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    return G\n",
    "\n",
    "def read_scores_from_file(filename):\n",
    "    scores = {}\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        n = int(next(file).strip())\n",
    "        \n",
    "        for _ in range(n):\n",
    "            v, j_count = map(int, next(file).strip().split(\" \")[:2])\n",
    "            scores[v] = {}\n",
    "\n",
    "            for _ in range(j_count):\n",
    "                line = next(file).strip().split(\" \")\n",
    "                scores[v][frozenset(map(int, line[2:]))] = float(line[0])\n",
    "\n",
    "    return scores\n",
    "\n",
    "def get_graph_hash(G: nx.Graph) -> str:\n",
    "    sorted_edges = sorted([tuple(edge) for edge in G.edges()])\n",
    "    edges_str = str(sorted_edges)\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(edges_str.encode())\n",
    "\n",
    "    return hash_object.hexdigest()\n",
    "# Get the default color cycle from Matplotlib\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "counter = 0\n",
    "# Function to get the next color from the default color cycle\n",
    "def get_next_color():\n",
    "    global counter\n",
    "    color = default_colors[counter % len(default_colors)]\n",
    "    counter += 1\n",
    "    return color\n",
    "\n",
    "# Works only for undirected\n",
    "# Edit: I think should work for both\n",
    "def get_graph_hash_ig(G: ig.Graph) -> str:\n",
    "    sorted_edges = sorted([tuple(sorted(edge)) for edge in G.get_edgelist()])\n",
    "    edges_str = str(sorted_edges)\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(edges_str.encode())\n",
    "\n",
    "    return hash_object.hexdigest()\n",
    "    \n",
    "memo = {}\n",
    "\n",
    "def memo_by_graph(G: nx.DiGraph, key: str, value):\n",
    "    if (key not in memo):\n",
    "        memo[key] = {}\n",
    "\n",
    "def plot(G, title=\"\"):\n",
    "    _, ax = plt.subplots()\n",
    "    visual_style = {}\n",
    "    visual_style[\"vertex_label\"] = list(map(lambda x: x, G.vs.indices))\n",
    "    ig.plot(G, target=ax, **visual_style)\n",
    "    plt.show()\n",
    "\n",
    "def get_es_diff(G1: ig.Graph, G2: ig.Graph):\n",
    "    G1_set = {e.tuple for e in G1.es}\n",
    "    G2_set = {e.tuple for e in G2.es}\n",
    "\n",
    "    both = G1_set.intersection(G2_set)\n",
    "    return (G1_set - both).union(G2_set - both)\n",
    "\n",
    "def seed(s):\n",
    "    np.random.seed(s * 1 + 1)\n",
    "    random.seed(s * 2 + 3)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "\n",
    "class REV:\n",
    "    def __init__(self, beta, score_manager: ScoreManager):\n",
    "        self.score_manager = score_manager\n",
    "        self.beta=beta\n",
    "\n",
    "    # Calculates Z (18)\n",
    "    def get_Z1(self, M: ig.Graph, X) -> (int, list[set]):\n",
    "        parent_sets = self.score_manager.scores[X].keys()\n",
    "\n",
    "        # Checks the descendants to find cycles\n",
    "        descendants = set(M.subcomponent(X, mode=\"out\")) - set({X})\n",
    "        parent_sets = list(filter(lambda parent_set: len(\n",
    "            parent_set & descendants) == 0, parent_sets))\n",
    "\n",
    "        return self.sum_scores(X, parent_sets)* self.beta, parent_sets\n",
    "\n",
    "    def sum_scores(self, X, parent_sets):\n",
    "        if (len(parent_sets) == 0):\n",
    "            return -np.inf\n",
    "        scores_dict = self.score_manager.scores[X]\n",
    "        scores = [scores_dict[pa] for pa in parent_sets]\n",
    "        return logsumexp(scores)\n",
    "\n",
    "    # Calculates Z (19)\n",
    "    def get_Z2(self, M, Xn, Xm) -> (int, list[set]):\n",
    "        parent_sets = self.score_manager.scores[Xn].keys()\n",
    "        # Checks the descendants to find cycles\n",
    "        descendants = set(M.subcomponent(Xn, mode=\"out\")) - set({Xn})\n",
    "        parent_sets = list(filter(lambda parent_set: self.I(parent_set, Xm) and len(\n",
    "            parent_set & descendants) == 0, parent_sets))\n",
    "\n",
    "        return self.sum_scores(Xn, parent_sets)*self.beta, parent_sets\n",
    "\n",
    "    def orphan_nodes(self, M, nodes):\n",
    "        M_prime = M.copy()\n",
    "        for node in nodes:\n",
    "            M_prime.delete_edges([(parent, node)\n",
    "                                  for parent in M.predecessors(node)])\n",
    "\n",
    "        return M_prime\n",
    "\n",
    "    def I(self, pa, Xj):\n",
    "        return Xj in pa\n",
    "\n",
    "    def new_edge_reversal_move(self, G: ig.Graph):\n",
    "        M = G.copy()\n",
    "        n = len(M.vs)\n",
    "\n",
    "        if (len(M.es) < 2):\n",
    "            return G, False\n",
    "\n",
    "        edge = np.random.choice(M.es)\n",
    "        Xi, Xj = edge.tuple\n",
    "\n",
    "        M_prime = self.orphan_nodes(M, [Xi, Xj])\n",
    "\n",
    "        ## Second step, sample parent set for Xi ##\n",
    "        Z2_i, parent_sets = self.get_Z2(M_prime, Xi, Xj)\n",
    "        Q_i_p = np.array([self.score_manager.get_local_score(Xi, frozenset(parent_set), n) -\n",
    "                          Z2_i for parent_set in parent_sets])\n",
    "\n",
    "        # Normalize probability\n",
    "        max_prob = np.max(Q_i_p)\n",
    "        Q_i_p_norm = np.exp(Q_i_p - max_prob)\n",
    "        Q_i_p_norm /= np.sum(Q_i_p_norm)\n",
    "\n",
    "        new_pi = np.random.choice(parent_sets, p=Q_i_p_norm)\n",
    "        M_plus = M_prime.copy()\n",
    "        edges = [(parent, Xi) for parent in new_pi]\n",
    "        M_plus.add_edges(edges)\n",
    "\n",
    "        ## Third step, sample patern set pj ##\n",
    "        Z1_j, parent_sets = self.get_Z1(M_plus, Xj)\n",
    "        Q_j_p = np.array([self.score_manager.get_local_score(Xj, frozenset(parent_set), n) -\n",
    "                          Z1_j for parent_set in parent_sets])\n",
    "        max_prob = np.max(Q_j_p)\n",
    "        Q_j_p_norm = np.exp(Q_j_p - max_prob)\n",
    "        Q_j_p_norm /= np.sum(Q_j_p_norm)\n",
    "\n",
    "        new_pj = np.random.choice(parent_sets, p=Q_j_p_norm)\n",
    "        M_tilda = M_plus.copy()\n",
    "        edges = [(parent, Xj) for parent in new_pj]\n",
    "        M_tilda.add_edges(edges)\n",
    "\n",
    "        if (np.random.uniform() < self.A(M, M_tilda, M_prime, Xi, Xj, Z2_i, Z1_j)):\n",
    "            return M_tilda, 'REV'\n",
    "\n",
    "        return G, False\n",
    "\n",
    "    # Acceptance rate\n",
    "    def A(self, M, M_tilda, M_prime, Xi, Xj, Z2_i, Z1_j):\n",
    "        first = (len(M.es) / len(M_tilda.es))\n",
    "        second = Z2_i - self.get_Z2(M_prime, Xj, Xi)[0]\n",
    "\n",
    "        M_tilda_plus = self.orphan_nodes(M, [Xi])\n",
    "        third = Z1_j - self.get_Z1(M_tilda_plus, Xi)[0]\n",
    "\n",
    "        #return np.min([1, first * np.exp(second + third)])\n",
    "        acceptance=np.min([0, np.log(first) + second + third])\n",
    "        return np.exp(acceptance)\n",
    "\n",
    "    \n",
    "#score_manager = ScoreManager('insurance50003p')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a3f48",
   "metadata": {
    "hideCode": false,
    "id": "483a3f48"
   },
   "source": [
    "### Functions for DAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481a610d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "481a610d",
    "outputId": "a7a1cd98-3494-4d2e-9af7-d444b081e8e9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def is_dag(adjacency_matrix):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    # Color codes: 0 for not visited, 1 for visiting, 2 for visited\n",
    "    colors = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    def dfs(node):\n",
    "        nonlocal colors\n",
    "\n",
    "        colors[node] = 1  # Mark the current node as visiting\n",
    "\n",
    "        for neighbor in np.where(adjacency_matrix[node] == 1)[0]:\n",
    "            if colors[neighbor] == 1:\n",
    "                return False  # Found a backward edge (cycle)\n",
    "            elif colors[neighbor] == 0:\n",
    "                if not dfs(neighbor):\n",
    "                    return False\n",
    "\n",
    "        colors[node] = 2  # Mark the current node as visited\n",
    "        return True\n",
    "\n",
    "    # Start DFS from each unvisited node\n",
    "    for node in range(num_nodes):\n",
    "        if colors[node] == 0:\n",
    "            if not dfs(node):\n",
    "                return False  # Found a cycle\n",
    "\n",
    "    return True  # No cycles found\n",
    "\n",
    "def generate_random_dag_adjacency_matrix(num_nodes,max_parents):\n",
    "    # Ensure a valid number of nodes\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"Number of nodes must be greater than 0.\")\n",
    "\n",
    "    # Randomly order the nodes\n",
    "    nodes = np.random.permutation(num_nodes)\n",
    "\n",
    "    # Initialize an empty adjacency matrix\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "    # Add edges to form a DAG\n",
    "    for i in range(num_nodes - 1):\n",
    "        # Randomly choose the number of edges from the current node\n",
    "        num_edges = np.random.randint(1, num_nodes - i)\n",
    "\n",
    "        # Randomly select nodes to connect\n",
    "        target_nodes = np.random.choice(nodes[i+1:], size=num_edges, replace=False)\n",
    "\n",
    "        # Add edges to the adjacency matrix\n",
    "        adjacency_matrix[nodes[i], target_nodes] = 1\n",
    "\n",
    "    new_dag= np.zeros((num_nodes,num_nodes),dtype=np.int8)\n",
    "    for i in range (num_nodes):\n",
    "        a=list(np.where(adjacency_matrix[:,i]==1)[0])\n",
    "        b=random.randint(0,max_parents)\n",
    "        c=random.sample(sorted(a), min(len(a),b))\n",
    "        for j in c:\n",
    "            new_dag[j,i]=1\n",
    "    #is_dag(new_dag)\n",
    "    #new_dag\n",
    "    return new_dag\n",
    "\n",
    "\n",
    "def dag_mean (x,start=0):\n",
    "    dim=(len(x[1][:,0,0]))\n",
    "    dag=np.zeros((len(x[1][:,0,0]),len(x[1][:,0,0])))\n",
    "    t=int(len(x[2])-1)\n",
    "    #print(t)\n",
    "    for i in range(start,t):\n",
    "        #print(i)\n",
    "        dag += x[1][:,:,i]\n",
    "    return dag/(len(x[2])-start) \n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80b820",
   "metadata": {
    "id": "cf80b820"
   },
   "source": [
    "### 1 step of MCMCMC\n",
    "\n",
    "The while cycle is useless now but It may be useful if I want to handle the constraints in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377f4e00",
   "metadata": {
    "id": "377f4e00"
   },
   "outputs": [],
   "source": [
    "from math import comb\n",
    "\n",
    "def mcmcmc (dag_now_p, loglik_now_p, prior_now_p, score_now_p,cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now,tot_swaps, max_parents\n",
    "\n",
    "    if beta==None:\n",
    "        beta=1\n",
    "    \n",
    "    dag0=np.copy(dag_now_p)\n",
    "    \n",
    "    condition=False\n",
    "    n_variables=len(dag_now_p[0])\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dag_now_p)\n",
    "        if (dag_now_p[u,v]==1) :\n",
    "            dag1[u,v]=0\n",
    "        elif (dag_now_p[v,u]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if (np.sum(dag_now_p[:,v])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dag_now_p[u,v]==0 and dag_now_p[v,u]==0):\n",
    "            dag1[u,v]=1\n",
    "            if np.sum(dag_now_p[:,v])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "    prior_0=1\n",
    "    loglik_0=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_1= prior_1*(1/comb((n_variables-1),np.sum(dag1[:,i])))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "        prior_0= prior_0*(1/comb((n_variables-1),np.sum(dag0[:,i])))\n",
    "        loglik_0+= cache[i][tuple(np.where(dag0[:,i]==1)[0])]\n",
    "    prior_1=np.log(prior_1)\n",
    "    prior_0=np.log(prior_0)\n",
    "    \n",
    "    #print(np.log(prior_1),loglik_1,np.log(prior_now_p),loglik_now_p)\n",
    "    \n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "    #print(np.exp(alpha))\n",
    "    #print((loglik_1-loglik_now_p),np.log(prior_1)-np.log(prior_now_p))\n",
    "    #print(np.exp(alpha))\n",
    "    #print(heating*(loglik_1-loglik_now_p)+np.log(prior_1)-np.log(prior_now_p))\n",
    "    rand=random.random()\n",
    "    #print(rand)\n",
    "\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "        if (loglik_1-loglik_0)!=0:\n",
    "            tot_swaps+=1\n",
    "            #print((loglik_1-loglik_now_p),np.log(prior_1)-np.log(prior_now_p))\n",
    "            #print(np.exp(alpha))\n",
    "        #print('accepted')\n",
    "        #print(dag_now-dag1)\n",
    "        dag_now=np.copy(dag1)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now= np.copy(loglik_1+prior_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcafba8",
   "metadata": {},
   "source": [
    "### REV step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ae9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def rev (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "    #print(dag0)\n",
    "    #dag0=dags_now_p[:,:,iterator]\n",
    "    #print(dag0)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "        #print(ind,ind[0][1])\n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        #print(indexes)\n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        #print(u,v)\n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "        #print(dag0)\n",
    "        #print(dag1)\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "        #print(dd_u)\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_u=list(set(dd_u))\n",
    "                #print(dd_u)\n",
    "        d_u=set(d_u)\n",
    "        #print(d_u,'d_u')\n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "            #rint(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_v=list(set(dd_v))\n",
    "                #print(dd_v)\n",
    "        d_v=set(d_v)\n",
    "        #print(d_v,'d_v')\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "        #print(pi_i_set,'before')\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "        #pi_i_tilde=random.sample(pi_i_set,1)[0]\n",
    "        #print(pi_i_set)\n",
    "        #print(pi_i_tilde)\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        #print(z_star_i_dot_j)\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "        #print(Z)\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        #print(Z)\n",
    "        #print(sample)\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "        #print('cross',dag_cross)\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_v=list(set(dd_v))\n",
    "                #print(dd_v)\n",
    "        d_v_plus=set(d_v_plus)\n",
    "        #print(d_v_plus,'d_v_plus')\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "        #pi_j_tilde=random.sample(pi_j_cross_set,1)[0]\n",
    "        \n",
    "        #print(pi_j_cross_set)\n",
    "        #print(pi_j_tilde)\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "        #print(Z)\n",
    "        #print(sample)\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "        #print(dag_tilde)\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "        #print(pi_j_set_2,'back')\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            z_star_j_dot_i.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "        #print(dag_tilde_cross)\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_u=list(set(dd_u))\n",
    "                #print(dd_v)\n",
    "        d_u_plus=set(d_u_plus)\n",
    "        #print(d_u_plus,'d_u_plus')\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "        #print('pi_i_cross_set',pi_i_cross_set)\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            z_i_cross.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "    #print(z_star_i_dot_j,z_j_cross,z_star_j_dot_i,z_i_cross)\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    #prior_0=1\n",
    "    #loglik_0=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        #prior_0= prior_0*(1/math.comb((n_variables-1),int(np.sum(dag0[:,i]))))\n",
    "        #loglik_0+= cache[i][tuple(np.where(dag0[:,i]==1)[0])]\n",
    "    #print(loglik_0+np.log(prior_0),loglik_1+np.log(prior_1))\n",
    "    #print(np.log(prior_1),loglik_1,np.log(prior_now_p),loglik_now_p)\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "    #alpha= min(beta*(loglik_1-loglik_0)+np.log(prior_1)-np.log(prior_0),0)\n",
    "    #print(np.exp(alpha),iterator)\n",
    "    #print(beta*(loglik_1-loglik_now_p[iterator]))\n",
    "    rand=random.random()\n",
    "    #print(np.exp(alpha),alpha)\n",
    "    if rand < np.exp(alpha):\n",
    "        #print('rev',iterator)\n",
    "        #print('accepted')\n",
    "        #print(dag_now-dag1)\n",
    "        dag_now=np.copy(dag_tilde)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=loglik_now+np.log(prior_now)\n",
    "    #print(score_now)\n",
    "        #if np.sum(np.abs(dag0-dag1))!=0:\n",
    "            #rev_tot+=1\n",
    "            #if iterator== (n_chains-1):\n",
    "                #rev_post+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d9caa",
   "metadata": {
    "id": "dc9d9caa"
   },
   "source": [
    "### Main function basic structure MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e11a19",
   "metadata": {
    "id": "51e11a19"
   },
   "outputs": [],
   "source": [
    "def structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, prob_rev=.1, seed=None):\n",
    "    global score_now,n_variables, dag_now, loglik_now, prior_now, tot_swaps, max_parents\n",
    "\n",
    "    n_variables=int(n_variables_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    tot_swaps=0\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dag_now= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    dags =np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    scores=np.zeros(n_iter)\n",
    "\n",
    "    prior_now=1\n",
    "    loglik_now=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_now= prior_now*(1/comb((n_variables-1),np.sum(dag_now[:,i])))\n",
    "        loglik_now+= cache[i][tuple(np.where(dag_now[:,i]==1)[0])]\n",
    "    \n",
    "    prior_now=np.log(prior_now)\n",
    "    score_now= loglik_now+prior_now\n",
    "\n",
    "    dags[:,:,0]=dag_now\n",
    "    scores[0]=score_now\n",
    "\n",
    "    for i in range(n_iter-1):\n",
    "        if random.random() > prob_rev:\n",
    "            mcmcmc(dag_now, loglik_now, prior_now, score_now, cache,1)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "        else:\n",
    "            #G=ig.Graph.Adjacency(dag_now)\n",
    "            #G=propose_next(G, True, 1, score_manager)[0]\n",
    "            #dag_now=np.array(ig.Graph.get_adjacency(G).data)\n",
    "            #dags[:,:,i+1]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "            #loglik_now, prior_now=score_manager.get_score(G)\n",
    "            #scores[i+1]= loglik_now+ prior_now\n",
    "            rev(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "    #print(tot_swaps,'swaps')\n",
    "\n",
    "    return scores,dags \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03814b8",
   "metadata": {
    "id": "f03814b8"
   },
   "source": [
    "### Functions for parallel tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb1113d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "6eb1113d",
    "outputId": "0c65506b-098f-4d8d-b05a-5f10f73627fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import splines\n",
    "\n",
    "x=[1,2,3,4,5]\n",
    "y=[1,4,4,11,19]\n",
    "pchip=scipy.interpolate.PchipInterpolator(x, y, axis=0, extrapolate=None)\n",
    "\n",
    "#X=np.arange(0,10,.1)\n",
    "#plt.plot(X,pchip(X))\n",
    "#plt.plot(x,y,'o')\n",
    "\n",
    "\n",
    "def bisection_at_x (f,a,b,x,max_iter=100,tol=1e-6):\n",
    "    for i in range (max_iter):\n",
    "        c = (a + b) / 2\n",
    "        if ((f(c) == x) or ((b - a) / 2 < tol)):\n",
    "            return(c)\n",
    "        if (f(c)< x):\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return (c)\n",
    "\n",
    "x=np.array([1,2,3,4,5])\n",
    "\n",
    "def y(x):\n",
    "    return x**2\n",
    "\n",
    "#bisection_at_x(y,1,5,3,100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56368ee5",
   "metadata": {
    "id": "56368ee5"
   },
   "source": [
    "### DEO main function (parallel tempering)\n",
    "\n",
    "1) t training steps are performed at the beginning to find the optimal number of chains and the values of the temperatures.\n",
    "\n",
    "2)  outputs: \\\n",
    "    a) dags and scores of the posterior during the training steps(post_dags, post_scores) \\\n",
    "    b) dags and scores of the posterior after the training steps(final_post_dags, final_post_scores) \\\n",
    "    c) dags and scores of each chain after the training steps (final_dags, final_scores) \\\n",
    "    d) the indexes of the chains to keep track of the swaps (indexes_matrix, indexes_matrix_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e038d9a4",
   "metadata": {
    "id": "e038d9a4"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "\n",
    "def deo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.2, seed=None, dynamic=True, geometric=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot, rand_steps\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "        #print(is_dag( dags_now[:,:,i]))\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            #print(i)\n",
    "            prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "\n",
    "    steps=0\n",
    "    counter=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "\n",
    "                if random.random() > prob_rev:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                    #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                    #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                    #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                    #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                    #print (loglik_now[j], prior_now[j])\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                        ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                        indexes_matrix_train[j,counter]=ind2\n",
    "                        indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            #print('after swap')\n",
    "            #print(loglik_now)\n",
    "\n",
    "            post_dags[:,:,counter]=dags_now[:,:,n_chains-1]\n",
    "            post_scores[counter]=loglik_now[n_chains-1]+prior_now[n_chains-1]\n",
    "            counter+=1\n",
    "            if counter <training_iter:\n",
    "                indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "            #print(dags_now[:,:,49]-dags_now[:,:,48])\n",
    "        #print('post',loglik_now[-1]+prior_now[-1])\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            #print(arr_lambda)\n",
    "            #print(betas)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "            #plt.plot(X,pchip(X))\n",
    "            #plt.show()\n",
    "    \n",
    "            #print(betas,'betas_before')\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "            #print(betas)\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "        #print(betas,'betas_after')\n",
    "\n",
    "    #print(steps,'steps')\n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "\n",
    "    #print('betas',betas)\n",
    "    #print('n_chains', n_chains)\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "    #steps=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            if random.random() > prob_rev:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            else:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                #print (loglik_now[j], prior_now[j])\n",
    "                #if prior_now[j]== np.nan:\n",
    "                #   print('nan')\n",
    "\n",
    "        \n",
    "        #print ('before_swap',loglik_now, prior_now)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            #print(alpha,j)\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                #print('before swap', loglik_now)\n",
    "                if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "                    #print('swap',j)\n",
    "                    ind1=np.copy(indexes_matrix[j,k])\n",
    "                    ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                    indexes_matrix[j,k]=ind2\n",
    "                    indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "                    #print('after swap', loglik_now)\n",
    "        #print ('after_swap',loglik_now, prior_now)\n",
    "        \n",
    "        #print(loglik_now)\n",
    "\n",
    "        for j in range (n_chains):\n",
    "            #if prior_now[j]== np.nan:\n",
    "                #print('nan')\n",
    "            final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "            final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "            #print(loglik_now[j]+np.log(prior_now[j]),loglik_now[j],np.log(prior_now[j]))\n",
    "            if j==(n_chains-1):\n",
    "                final_post_dags[:,:,k]=dags_now[:,:,j]\n",
    "                final_post_scores[k]=loglik_now[j]+prior_now[j]\n",
    "                #print('post',final_post_scores[k])\n",
    "        if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//3000)<8) and geometric==False):\n",
    "            if k%3000==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                #print(arr_lambda)\n",
    "                #print(betas)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                #print(betas,'betas')\n",
    "                #print(r,'r')\n",
    "                #print(loglik_now[-1]+prior_now[-1],'score post')\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "                #plt.plot(X,pchip(X))\n",
    "                #plt.show()\n",
    "    \n",
    "                #print(betas,'betas_before')\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                #print(betas)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "\n",
    "\n",
    "\n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R,'r')\n",
    "    print(betas,'betas')\n",
    "    #arr_lambda= np.cumsum(r)\n",
    "    #lambda_1=arr_lambda[-1]\n",
    "    #r_star=lambda_1/(n_chains-1)\n",
    "\n",
    "    #pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "    #X=np.arange(0,1,.001)\n",
    "    #plt.plot(X,pchip(X))\n",
    "    #plt.show()\n",
    "\n",
    "    #print(steps,'steps_after')\n",
    "    #print(rev_post,'rev_post')\n",
    "    #print(rev_tot,'rev_tot')\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    \n",
    "    #return tot_post, final_post_dags, final_post_scores, final_dags, final_scores, post_dags, post_scores, indexes_matrix, indexes_matrix_train, n_chains, r\n",
    "    return tot_post, final_post_dags, indexes_matrix, n_chains, r,R,betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b72cbf",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "### SEO main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76861656",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "\n",
    "def seo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.2, seed=None,dynamic=True, geometric=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot, rand_steps\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "\n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "    \n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "\n",
    "    steps=0\n",
    "    counter=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            \n",
    "            K=random.random()\n",
    "            if K<.5:\n",
    "                K=1\n",
    "            else:\n",
    "                K=2\n",
    "                \n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "\n",
    "                if random.random() > prob_rev:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                    #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                    #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                    #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                    #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                    #print (loglik_now[j], prior_now[j])\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                        ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                        indexes_matrix_train[j,counter]=ind2\n",
    "                        indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            #print('after swap')\n",
    "            #print(loglik_now)\n",
    "\n",
    "            post_dags[:,:,counter]=dags_now[:,:,n_chains-1]\n",
    "            post_scores[counter]=loglik_now[n_chains-1]+prior_now[n_chains-1]\n",
    "            counter+=1\n",
    "            if counter <training_iter:\n",
    "                indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "            #print(dags_now[:,:,49]-dags_now[:,:,48])\n",
    "        #print('post',loglik_now[-1]+prior_now[-1])\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            #print(arr_lambda)\n",
    "            #print(betas)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "            #plt.plot(X,pchip(X))\n",
    "            #plt.show()\n",
    "    \n",
    "            #print(betas,'betas_before')\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "            #print(betas)\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "            #print(betas,'betas_after')\n",
    "\n",
    "    #print(steps,'steps')\n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    \n",
    "        #print('betas',betas)\n",
    "        #print('n_chains', n_chains)\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "    #steps=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        K=random.random()\n",
    "        if K<.5:\n",
    "            K=1\n",
    "        else:\n",
    "            K=2\n",
    "        \n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            if random.random() > prob_rev:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            else:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                #print (loglik_now[j], prior_now[j])\n",
    "                #if prior_now[j]== np.nan:\n",
    "                #   print('nan')\n",
    "\n",
    "        \n",
    "        #print ('before_swap',loglik_now, prior_now)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            #print(alpha,j)\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                #print('before swap', loglik_now)\n",
    "                if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                    #print('swap',j)\n",
    "                    ind1=np.copy(indexes_matrix[j,k])\n",
    "                    ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                    indexes_matrix[j,k]=ind2\n",
    "                    indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "                    #print('after swap', loglik_now)\n",
    "        #print ('after_swap',loglik_now, prior_now)\n",
    "        \n",
    "        #print(loglik_now)\n",
    "\n",
    "        for j in range (n_chains):\n",
    "            #if prior_now[j]== np.nan:\n",
    "                #print('nan')\n",
    "            final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "            final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "            #print(loglik_now[j]+np.log(prior_now[j]),loglik_now[j],np.log(prior_now[j]))\n",
    "            if j==(n_chains-1):\n",
    "                final_post_dags[:,:,k]=dags_now[:,:,j]\n",
    "                final_post_scores[k]=loglik_now[j]+prior_now[j]\n",
    "                #print('post',final_post_scores[k])\n",
    "        if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//3000)<8) and geometric==False):\n",
    "\n",
    "            if k%3000==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                #print(arr_lambda)\n",
    "                #print(betas)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                #print(betas,'betas')\n",
    "                #print(r,'r')\n",
    "                #print(loglik_now[-1]+prior_now[-1],'score post')\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "                #plt.plot(X,pchip(X))\n",
    "                #plt.show()\n",
    "    \n",
    "                #print(betas,'betas_before')\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                #print(betas)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "\n",
    "\n",
    "\n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R,'r')\n",
    "    print(betas,'betas')\n",
    "    #arr_lambda= np.cumsum(r)\n",
    "    #lambda_1=arr_lambda[-1]\n",
    "    #r_star=lambda_1/(n_chains-1)\n",
    "\n",
    "    #pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "    #X=np.arange(0,1,.001)\n",
    "    #plt.plot(X,pchip(X))\n",
    "    #plt.show()\n",
    "\n",
    "    #print(steps,'steps_after')\n",
    "    #print(rev_post,'rev_post')\n",
    "    #print(rev_tot,'rev_tot')\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    \n",
    "    #return tot_post, final_post_dags, final_post_scores, final_dags, final_scores, post_dags, post_scores, indexes_matrix, indexes_matrix_train,n_chains, r\n",
    "    return tot_post, final_post_dags, indexes_matrix, n_chains, r,R,betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15109c2b",
   "metadata": {},
   "source": [
    "### Random swap PT main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359a5648",
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "\n",
    "def rand_pt_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.2, seed=None,dynamic=True,geometric=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot, rand_steps\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "\n",
    "    steps=0\n",
    "    counter=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "\n",
    "                if random.random() > prob_rev:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                    #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                    #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                    #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                    #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                    #print (loglik_now[j], prior_now[j])\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    K=random.random()\n",
    "                    if (K<.5):\n",
    "                        #print('swap',j)\n",
    "                        ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                        ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                        indexes_matrix_train[j,counter]=ind2\n",
    "                        indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            #print('after swap')\n",
    "            #print(loglik_now)\n",
    "\n",
    "            post_dags[:,:,counter]=dags_now[:,:,n_chains-1]\n",
    "            post_scores[counter]=loglik_now[n_chains-1]+prior_now[n_chains-1]\n",
    "            counter+=1\n",
    "            if counter <training_iter:\n",
    "                indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "            #print(dags_now[:,:,49]-dags_now[:,:,48])\n",
    "        #print('post',loglik_now[-1]+prior_now[-1])\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            #print(arr_lambda)\n",
    "            #print(betas)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "            #plt.plot(X,pchip(X))\n",
    "            #plt.show()\n",
    "    \n",
    "            #print(betas,'betas_before')\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "            #print(betas)\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "            #print(betas,'betas_after')\n",
    "\n",
    "    #print(steps,'steps')\n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    \n",
    "    #print('betas',betas)\n",
    "    #print('n_chains', n_chains)\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "    #steps=0\n",
    "    rev_post=0\n",
    "    rev_tot=0\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        \n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            if random.random() > prob_rev:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            else:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                #G=ig.Graph.Adjacency(dags_now[:,:,j])\n",
    "                #G=propose_next(G, True, betas[j], score_manager)[0]\n",
    "                #dags_now[:,:,j]=np.array(ig.Graph.get_adjacency(G).data)\n",
    "                #loglik_now[j], prior_now[j]=score_manager.get_score(G)\n",
    "                #print (loglik_now[j], prior_now[j])\n",
    "                #if prior_now[j]== np.nan:\n",
    "                #   print('nan')\n",
    "\n",
    "        \n",
    "        #print ('before_swap',loglik_now, prior_now)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            #print(alpha,j)\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                K=random.random()\n",
    "                #print('before swap', loglik_now)\n",
    "                if (K<.5):\n",
    "                    #print('swap',j)\n",
    "                    ind1=np.copy(indexes_matrix[j,k])\n",
    "                    ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                    indexes_matrix[j,k]=ind2\n",
    "                    indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "                    #print('after swap', loglik_now)\n",
    "        #print ('after_swap',loglik_now, prior_now)\n",
    "        \n",
    "        #print(loglik_now)\n",
    "\n",
    "        for j in range (n_chains):\n",
    "            #if prior_now[j]== np.nan:\n",
    "                #print('nan')\n",
    "            final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "            final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "            #print(loglik_now[j]+np.log(prior_now[j]),loglik_now[j],np.log(prior_now[j]))\n",
    "            if j==(n_chains-1):\n",
    "                final_post_dags[:,:,k]=dags_now[:,:,j]\n",
    "                final_post_scores[k]=loglik_now[j]+prior_now[j]\n",
    "                #print('post',final_post_scores[k])\n",
    "        if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//3000)<8 )and geometric==False):\n",
    "\n",
    "            if k%3000==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                #print(arr_lambda)\n",
    "                #print(betas)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                #print(betas,'betas')\n",
    "                #print(r,'r')\n",
    "                #print(loglik_now[-1]+prior_now[-1],'score post')\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "                #plt.plot(X,pchip(X))\n",
    "                #plt.show()\n",
    "    \n",
    "                #print(betas,'betas_before')\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                #print(betas)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "\n",
    "\n",
    "\n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print('r',R)\n",
    "    print('betas', betas)\n",
    "    #arr_lambda= np.cumsum(r)\n",
    "    #lambda_1=arr_lambda[-1]\n",
    "    #r_star=lambda_1/(n_chains-1)\n",
    "\n",
    "    #pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "    #X=np.arange(0,1,.001)\n",
    "    #plt.plot(X,pchip(X))\n",
    "    #plt.show()\n",
    "\n",
    "    #print(steps,'steps_after')\n",
    "    #print(rev_post,'rev_post')\n",
    "    #print(rev_tot,'rev_tot')\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    \n",
    "    #return tot_post, final_post_dags, final_post_scores, final_dags, final_scores, post_dags, post_scores, indexes_matrix, indexes_matrix_train, n_chains, r\n",
    "    return tot_post, final_post_dags, indexes_matrix, n_chains, r,R, betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae7ab4",
   "metadata": {},
   "source": [
    "### Random step parallel temprering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bf5f9b",
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def pt_random (dags_now_p, loglik_now_p, prior_now_p, beta):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot, rand_steps\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    \n",
    "    dag1= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=1\n",
    "    loglik_0=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "        prior_0= prior_0*(1/math.comb((n_variables-1),int(np.sum(dag0[:,i]))))\n",
    "        loglik_0+= cache[i][tuple(np.where(dag0[:,i]==1)[0])]\n",
    "\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+np.log(prior_1)-np.log(prior_0),0)\n",
    "    \n",
    "    rand=random.random()\n",
    "    \n",
    "    print(np.exp(alpha),iterator)\n",
    "    \n",
    "    if rand < np.exp(alpha):\n",
    "        if (np.sum(np.abs(dags_now_p[:,:,iterator]-dag1))!=0) :\n",
    "            steps+=1\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = prior_1\n",
    "        loglik_now[iterator]= loglik_1\n",
    "        #print(dags_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c1f9d",
   "metadata": {
    "id": "438c1f9d"
   },
   "source": [
    "### MCMCMC step parallel tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32eb188a",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "32eb188a"
   },
   "outputs": [],
   "source": [
    "def pt_mcmcmc (dags_now_p, loglik_now_p, prior_now_p, beta,cache):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot, rand_steps\n",
    "\n",
    "    condition=False\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "        if (dags_now_p[u,v,iterator]==1) :\n",
    "            dag1[u,v]=0\n",
    "\n",
    "        elif (dags_now_p[v,u,iterator]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if  (np.sum(dags_now_p[:,v,iterator])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "                #continue\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dags_now_p[u,v,iterator]==0 and dags_now_p[v,u,iterator]==0):\n",
    "            dag1[u,v]=1\n",
    "            if  np.sum(dags_now_p[:,v,iterator])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "                #continue\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=1\n",
    "    loglik_0=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "        prior_0= prior_0*(1/math.comb((n_variables-1),int(np.sum(dag0[:,i]))))\n",
    "        loglik_0+= cache[i][tuple(np.where(dag0[:,i]==1)[0])]\n",
    "        \n",
    "    prior_0=np.log(prior_0)\n",
    "    prior_1=np.log(prior_1)\n",
    "    ###print(np.log(prior_1),loglik_1,np.log(prior_0),loglik_0)\n",
    "    #if iterator==n_chains -1:\n",
    "        #print ('post')\n",
    "        #print(dag1-dags_now_p[:,:,iterator])\n",
    "    #print(iterator,dags_now_p[:,:,iterator])\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "    #print(beta*(loglik_1-loglik_now_p[iterator]),'lik')\n",
    "    #print(np.log(prior_1)-np.log(prior_now_p[iterator]),'prior')\n",
    "    #print(loglik_1,loglik_now[iterator])\n",
    "    ###print(np.exp(alpha),'alpha',iterator)\n",
    "    #print(np.exp(alpha))\n",
    "    #print(heating*(loglik_1-loglik_now_p)+np.log(prior_1)-np.log(prior_now_p))\n",
    "    rand=random.random()\n",
    "    #print(rand)\n",
    "    #print(np.log(prior_1),loglik_1,np.log(prior_now_p[iterator]),loglik_now_p[iterator])\n",
    "    #print(np.sum(np.abs(dags_now_p[:,:,iterator]-dag1)),np.exp(alpha),'alpha',iterator)\n",
    "    if rand < np.exp(alpha):\n",
    "        #print('accepted')\n",
    "        #print(dags_now[:,:,iterator]-dag1)\n",
    "        #print('mc3',iterator)\n",
    "        #if np.sum(dag1 -dags_now_p[:,:,iterator])!=0:\n",
    "        #    print(np.log(prior_1),loglik_1,np.log(prior_now_p[iterator]),loglik_now_p[iterator])\n",
    "        #   print(np.exp(alpha),'alpha',iterator)\n",
    "        #print(dags_now_p[:,:,iterator]-dag1)\n",
    "        if (np.sum(np.abs(dags_now_p[:,:,iterator]-dag1))!=0) :\n",
    "            steps+=1\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = prior_1\n",
    "        loglik_now[iterator]= loglik_1\n",
    "        #print(dags_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a43e4e",
   "metadata": {
    "id": "69a43e4e"
   },
   "source": [
    "### REV step parallel tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b00cceb",
   "metadata": {
    "hideCode": false,
    "id": "4b00cceb"
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def pt_rev (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    #print(dag0)\n",
    "    #dag0=dags_now_p[:,:,iterator]\n",
    "    #print(dag0)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "        #print(ind,ind[0][1])\n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        #print(indexes)\n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        #print(u,v)\n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "        #print(dag0)\n",
    "        #print(dag1)\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "        #print(dd_u)\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_u=list(set(dd_u))\n",
    "                #print(dd_u)\n",
    "        d_u=set(d_u)\n",
    "        #print(d_u,'d_u')\n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "            #rint(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_v=list(set(dd_v))\n",
    "                #print(dd_v)\n",
    "        d_v=set(d_v)\n",
    "        #print(d_v,'d_v')\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "        #print(pi_i_set,'before')\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "        #pi_i_tilde=random.sample(pi_i_set,1)[0]\n",
    "        #print(pi_i_set)\n",
    "        #print(pi_i_tilde)\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        #print(z_star_i_dot_j)\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "        #print(Z)\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        #print(Z)\n",
    "        #print(sample)\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "        #print('cross',dag_cross)\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_v=list(set(dd_v))\n",
    "                #print(dd_v)\n",
    "        d_v_plus=set(d_v_plus)\n",
    "        #print(d_v_plus,'d_v_plus')\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "        #pi_j_tilde=random.sample(pi_j_cross_set,1)[0]\n",
    "        \n",
    "        #print(pi_j_cross_set)\n",
    "        #print(pi_j_tilde)\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "        #print(Z)\n",
    "        #print(sample)\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "        #print(dag_tilde)\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "        #print(pi_j_set_2,'back')\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            z_star_j_dot_i.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "        #print(dag_tilde_cross)\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "        #print(dd_v)\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "            #print(child,'child')\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "                    #print(nephew,'nephew')\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "                #print(dd_u)\n",
    "                dd_u=list(set(dd_u))\n",
    "                #print(dd_v)\n",
    "        d_u_plus=set(d_u_plus)\n",
    "        #print(d_u_plus,'d_u_plus')\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "        #print('pi_i_cross_set',pi_i_cross_set)\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            z_i_cross.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "    #print(z_star_i_dot_j,z_j_cross,z_star_j_dot_i,z_i_cross)\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    #prior_0=1\n",
    "    #loglik_0=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        #prior_0= prior_0*(1/math.comb((n_variables-1),int(np.sum(dag0[:,i]))))\n",
    "        #loglik_0+= cache[i][tuple(np.where(dag0[:,i]==1)[0])]\n",
    "    #print(loglik_0+np.log(prior_0),loglik_1+np.log(prior_1))\n",
    "    #print(np.log(prior_1),loglik_1,np.log(prior_now_p),loglik_now_p)\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "    #alpha= min(beta*(loglik_1-loglik_0)+np.log(prior_1)-np.log(prior_0),0)\n",
    "    #print(np.exp(alpha),iterator)\n",
    "    #print(beta*(loglik_1-loglik_now_p[iterator]))\n",
    "    rand=random.random()\n",
    "    #print(np.exp(alpha),alpha)\n",
    "    if rand < np.exp(alpha):\n",
    "        #print('rev',iterator)\n",
    "        #print('accepted')\n",
    "        #print(dag_now-dag1)\n",
    "        dags_now[:,:,iterator]=np.copy(dag_tilde)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n",
    "        #score_now=loglik_now+prior_now\n",
    "    #print(score_now)\n",
    "        #if np.sum(np.abs(dag0-dag1))!=0:\n",
    "            #rev_tot+=1\n",
    "            #if iterator== (n_chains-1):\n",
    "                #rev_post+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d65b",
   "metadata": {},
   "source": [
    "### Diagnostic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d63b57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restarts(chain):\n",
    "    rest=0\n",
    "    ground=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        ground[int(chain[2][0,i])]=1\n",
    "        #print(ground)\n",
    "        if ground[int(chain[2][chain[3]-1,i])]==1:\n",
    "            ground[int(chain[2][chain[3]-1,i])]=0\n",
    "            rest+=1\n",
    "    #print(ground)\n",
    "    return rest\n",
    "\n",
    "def plot_swaps (chain):\n",
    "    a=[]\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        a.append(int(np.where(chain[2][:,i]==2)[0]))\n",
    "    plt.plot(a)\n",
    "    plt.show()\n",
    "    \n",
    "def dag_mean (x,start=0):\n",
    "    dim=len(x[1][:,0,0])\n",
    "    dag=np.zeros((dim,dim))\n",
    "    t=len(x[1][0,0,:])\n",
    "    #print(dag)\n",
    "    for i in range(start,t):\n",
    "        #print(x[1][:,:,i])\n",
    "        dag += x[1][:,:,i]\n",
    "    return dag/(len(x[0])-start) \n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "def mixing_ratio(chain):\n",
    "    ratio_post=0\n",
    "    ratio=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        #print(chain[2][:,i])\n",
    "        for j in range(chain[3]):\n",
    "            ratio[int(chain[2][j,i])]+=(chain[3]-1-j)/(chain[3])\n",
    "        ratio_post+= ratio[int(chain[2][chain[3]-1,i])]\n",
    "        ratio[int(chain[2][chain[3]-1,i])]=0\n",
    "        #print(ratio)\n",
    "        #print(ratio_post)\n",
    "    return ratio_post/len(chain[2][0,:])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
